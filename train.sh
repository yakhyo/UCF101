python3 -m torch.distributed.run --nproc_per_node=2 train.py --amp --cache-dataset